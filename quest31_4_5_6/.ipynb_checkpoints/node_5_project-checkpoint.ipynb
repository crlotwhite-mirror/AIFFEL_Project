{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd18726",
   "metadata": {},
   "source": [
    "## 5. 뉴스 카테고리 다중분류-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fab4835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:06:25.341621: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df0abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c49666",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "def reuters_load_ml(num_words):\n",
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
    "    \n",
    "    decoded = []\n",
    "    for i in range(len(x_train)):\n",
    "        t = ' '.join([index_to_word[i] for index in x_train[i]])\n",
    "        decoded.append(t)\n",
    "\n",
    "    x_train = decoded\n",
    "    \n",
    "    decoded = []\n",
    "    for i in range(len(x_test)):\n",
    "        t = ' '.join([index_to_word[i] for index in x_test[i]])\n",
    "        decoded.append(t)\n",
    "\n",
    "    x_test = decoded\n",
    "    \n",
    "    x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "    x_train = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "    x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "    x_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4c1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ml(x_train, y_train, x_test, y_test):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    predicted = nb.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    \n",
    "    cb = ComplementNB()\n",
    "    cb.fit(x_train, y_train)\n",
    "    predicted = cb.predict(x_test)\n",
    "    \n",
    "    lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "    lr.fit(x_train, y_train)\n",
    "    predicted = lr.predict(x_test)\n",
    "    \n",
    "    lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "    lsvc.fit(x_train, y_train)\n",
    "    predicted = lsvc.predict(x_test)\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "    tree.fit(x_train, y_train)\n",
    "    predicted = tree.predict(x_test)\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "    forest.fit(x_train, y_train)\n",
    "    predicted = forest.predict(x_test)\n",
    "    \n",
    "    grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "    grbt.fit(x_train, y_train)\n",
    "    predicted = grbt.predict(x_test)\n",
    "    \n",
    "    clf1 = LogisticRegression()\n",
    "    clf2 = ComplementNB()\n",
    "    clf3 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "    voting_classifier = VotingClassifier(estimators=[('lr', clf1), ('gnb', clf2), ('dt', clf3)], voting='hard')\n",
    "    voting_classifier.fit(x_train, y_train)\n",
    "    predicted = voting_classifier.predict(x_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce75380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mreuters_load_ml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#fit_ml(x_train, y_train, x_test, y_test)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreuters_load_ml\u001b[0;34m(num_words)\u001b[0m\n\u001b[1;32m      7\u001b[0m decoded \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_train)):\n\u001b[0;32m----> 9\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([index_to_word[i] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m x_train[i]])\n\u001b[1;32m     10\u001b[0m     decoded\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m     12\u001b[0m x_train \u001b[38;5;241m=\u001b[39m decoded\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m decoded \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_train)):\n\u001b[0;32m----> 9\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mindex_to_word\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m x_train[i]])\n\u001b[1;32m     10\u001b[0m     decoded\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m     12\u001b[0m x_train \u001b[38;5;241m=\u001b[39m decoded\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = reuters_load_ml(None)\n",
    "#fit_ml(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = reuters_load_ml(None)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "\n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(None)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "\n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(10000)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "\n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(10000)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(50000)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(5000)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e7ff1",
   "metadata": {},
   "source": [
    "## F1-Score, Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc9520",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2249c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(tfidfv_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ef6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fccee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_confusion_matrix(model, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257772af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
